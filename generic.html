<!DOCTYPE HTML>
<!--
	Phantom by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Amelia Konomos- Scientific projects</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">
		<!-- Wrapper -->
		<div id="wrapper">

			<!-- Header -->
			<header id="header">
				<div class="inner">

					<!-- Logo -->
					<a href="index.html" class="logo">
						<span class="symbol"></span><span class="title">Home</span>
					</a>

					<!-- Nav -->
					<nav>
						<ul>
							<li><a href="#menu">Menu</a></li>
						</ul>
					</nav>

				</div>
			</header>

			<!-- Menu -->
			<nav id="menu">
				<h2>Menu</h2>
				<ul>
					<li><a href="index.html">Home</a></li>
					<li><a href="generic.html">Data Engineering</a></li>
					<li><a href="generic2.html">Data Analytics</a></li>
					<li><a href="generic3.html">UX/UI Design </a></li>

				</ul>
			</nav>
			
					<div id="main">
				<div class="inner">
					<span class="image main"><img src="images/ap.png" alt="" /></span>
					<h1>API Integration: Pulling live data to track the international space system.</h1>
					<h5>Tools used: Python, ISS API, Pycharm, and pandas libraries</h5> 
					</p>

					<!-- Footer -->


				</div>


			<div id="main">
				<div class="inner">
					<span class="image main"><img src="images/roman.jpg" alt="" /></span>
					<h1>Roman Space Telescope: Building data pipelines and advancing algorithms for NASA's next flagship mission.</h1>
					<h5>Tools used: Python, EMCCD Detect pipeline, matplotlib, pickle, scipy, and pandas libraries</h5> 
					</p>
					<h5>Background:</h5> The Roman Space Telescope is NASA’s next flagship mission designed to investigate dark energy, dark matter, and exoplanets. With its novel Coronagraph Instrument, the telescope will perform direct imaging of exoplanets and give us deeper insight into the existence of such distant worlds. Roman is unique for several reasons, the first being its special Coronagraph instrument technology which is currently being built at JPL. Its Coronagraph technology will block starlight from the host star in order to image the orbiting exoplanet. This technology demonstration phase will last 18 months and after will be open to the wider scientific community for future use. Roman is also unique in that its wide field view is about 100 times that of Hubble and 36 times the size of the James Webb’s Qunintet image. With its novel technology, Roman is expected to observe giant exoplanets in reflected light at unprecedented contrast gain levels.
					</p>
					<h5>Why are post-processing algorithms important:</h5> The main challenge of direct imaging is the removal of the residual starlight from the image. Using just the Coronagraph instrument for imaging is not sufficient as this technology cannot solve errors like image deterioration and surface deformations, so post processing pipelines and algorithms are essential in reducing background noise and successfully detecting the planet within the raw image data. It is also necessary to reach the contrast that is needed to demonstrate the technology. Post-processing data pipelines and their resulting contrast gain numbers for Roman are very important its direct imaging will take place at an unprecedented contrast gain level. There are currently 3 different post-processing techniques being tested for use on the Roman simulated data. My project plays an important role in verifying and confirming the efficacy of the Roman Coronagraph instrument and my results will help to determine the best algorithms and processing techniques. Testing post-processing techniques on the last set of simulated data and its contrasts will give the Roman team confidence that they will be able to demonstrate the technology.
					<h5>Project Goal:</h5> The purpose of my project is to advance and improve the current post-processing data pipelines on a single simulated dataset and obtain a metric of success for the Coronagraph Instrument. Our data concerns the OS-11 data for the Hybrid Lyot Coronagraph Band 1 which encompasses observations of a bright reference star Zeta Pup and a science target star 47 Uma. My final deliverable is a contrast table with contrast gain numbers for each of the 3 processing techniques on the OS-11 data. These contrast gain numbers are paramount in verifying and confirming the efficacy of the Roman Coronagraph Instrument before launch.
					</p>
					<h5>PRE PROCESSING of data: </h5> The pre-processing procedure of data involves writing a script in python that interpolates 22 data cube images over time. The large data set we worked with is called OS-11. My pre-processing procedure includes normalization, image interpolation, an EMCCD routine, and a photon counting routine. We began the project with a master data cube of raw simulated images. These images needed to be interpolated to the correct exposure times since the raw data were for a longer exposure time than actually needed. In order to reduce the data, we separated the raw data into 22 smaller data cubes as keys under one encompassing dictionary. The image separation was based on the OS-11 Nomenclature which separated batch IDs into references and target images. The reference star images have batch IDs starting with 0 and incrementing by 1 with each visit while the target star images have batch IDs starting with 100 and increasing by 1 with every roll. Each cycle of target imaging begins at the next increment of 100. Before even attempting interpolation of the data, it was necessary to separate the data into smaller, more manageable increments as numpy array data types. For each of the 22 batch IDs, we created an initial cadence and a final cadence array as numpy array data types. The initial cadences were created within a for loop that iterated through each batch ID and returned new arrays of the respective batch ID shape. Finally, with these three dictionaries we were able to run the interpolation on 22 data cubes. 
					</p>
					<h5>Post processing of data</h5> 
					</p> Once interpolation was complete, the next step was to pass my two, 3D master data cubes through the EMCCD detect data pipeline. EMCCD detect is a python package for EMCCD modeling provided by Bijan Nemati, Sam Miller, and Kevin Ludwick. Given an input fluxmap, EMCCD detect python package will return a simulated EMCCD detector image. We ran the EMCCD routine within another HLC python package which adds noise to the data. Its output is 3 new FITS files as 4D data cubes with the fourth dimension being the batch ID. 
					<h5>results:</h5> Finally, once completing all of the pre and post processing procedures, we were able to produce an output table with a summary of contrasts, gains, and FAC for one of the OS-11 data sets. These data simulations and post-processing routines are part of an ongoing project. Since we have obtained multiple contrast gain numbers for the other OS-11 data sets, we will need to complete several cross-checks of the cubes and determine the error in the noiseless data. There is still work to be done before the launch of Roman in 2027, and the team will continue to advance and develop processing techniques. 

					<!-- Footer -->


				</div>




</div>

				<!-- Scripts -->
				<script src="assets/js/jquery.min.js"></script>
				<script src="assets/js/browser.min.js"></script>
				<script src="assets/js/breakpoints.min.js"></script>
				<script src="assets/js/util.js"></script>
				<script src="assets/js/main.js"></script>

</body>
</html>
